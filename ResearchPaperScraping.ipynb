{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install beautifulsoup4 requests\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "akbWjPtsXBqZ",
        "outputId": "33785612-aa37-4ad2-d2e2-3c0a2540cd50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.12.14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "\n",
        "def fetch_google_scholar_papers(staff_name, college_name):\n",
        "    search_url = f\"https://scholar.google.com/scholar?q={staff_name.replace(' ', '+')}+{college_name.replace(' ', '+')}\"\n",
        "    papers = []\n",
        "\n",
        "    try:\n",
        "        response = requests.get(search_url, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
        "        response.raise_for_status()\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "        for result in soup.select('.gs_ri'):\n",
        "            title = result.select_one('.gs_rt').text if result.select_one('.gs_rt') else \"No Title\"\n",
        "            link = result.select_one('.gs_rt a')['href'] if result.select_one('.gs_rt a') else \"No Link\"\n",
        "            citations = result.select_one('.gs_fl').text if result.select_one('.gs_fl') else \"No Citations\"\n",
        "            papers.append({\"title\": title, \"link\": link, \"citations\": citations})\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching from Google Scholar: {e}\")\n",
        "\n",
        "    return papers\n",
        "\n",
        "def fetch_researchgate_papers(staff_name):\n",
        "    search_url = f\"https://www.researchgate.net/search/publication?q={staff_name.replace(' ', '%20')}\"\n",
        "    papers = []\n",
        "\n",
        "    try:\n",
        "        response = requests.get(search_url, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
        "        response.raise_for_status()\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "        for result in soup.select('.publication-item'):\n",
        "            title_elem = result.select_one('.publication-title')\n",
        "            title = title_elem.text.strip() if title_elem else \"No Title\"\n",
        "            link = \"https://www.researchgate.net\" + title_elem.find('a')['href'] if title_elem else \"No Link\"\n",
        "            papers.append({\"title\": title, \"link\": link, \"citations\": \"N/A\"})\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching from ResearchGate: {e}\")\n",
        "\n",
        "    return papers\n",
        "\n",
        "def fetch_academia_papers(staff_name):\n",
        "    search_url = f\"https://www.academia.edu/search?q={staff_name.replace(' ', '%20')}\"\n",
        "    papers = []\n",
        "\n",
        "    try:\n",
        "        response = requests.get(search_url, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
        "        response.raise_for_status()\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "        for result in soup.select('.paper'):\n",
        "            title_elem = result.select_one('.title')\n",
        "            title = title_elem.text.strip() if title_elem else \"No Title\"\n",
        "            link = title_elem.find('a')['href'] if title_elem else \"No Link\"\n",
        "            papers.append({\"title\": title, \"link\": link, \"citations\": \"N/A\"})\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching from Academia.edu: {e}\")\n",
        "\n",
        "    return papers\n",
        "\n",
        "def fetch_web_of_science_papers(staff_name, college_name):\n",
        "    search_url = f\"https://www.webofscience.com/wos/woscc/advanced-search?query={staff_name.replace(' ', '+')}+AND+{college_name.replace(' ', '+')}\"\n",
        "    papers = []\n",
        "\n",
        "    try:\n",
        "        response = requests.get(search_url, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
        "        response.raise_for_status()\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "        # Scrape paper titles and citations from Web of Science\n",
        "        for result in soup.select('.search-results-item'):\n",
        "            title_elem = result.select_one('.title')\n",
        "            title = title_elem.text.strip() if title_elem else \"No Title\"\n",
        "            link = \"https://www.webofscience.com\" + title_elem.find('a')['href'] if title_elem else \"No Link\"\n",
        "            citations = result.select_one('.citations').text.strip() if result.select_one('.citations') else \"N/A\"\n",
        "            papers.append({\"title\": title, \"link\": link, \"citations\": citations})\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching from Web of Science: {e}\")\n",
        "\n",
        "    return papers\n",
        "\n",
        "def fetch_semantic_scholar_papers(staff_name):\n",
        "    search_url = f\"https://www.semanticscholar.org/search?q={staff_name.replace(' ', '%20')}\"\n",
        "    papers = []\n",
        "\n",
        "    try:\n",
        "        response = requests.get(search_url, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
        "        response.raise_for_status()\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "        for result in soup.select('.cl-paper-row'):\n",
        "            title_elem = result.select_one('.cl-paper-title')\n",
        "            title = title_elem.text.strip() if title_elem else \"No Title\"\n",
        "            link = \"https://www.semanticscholar.org\" + title_elem.find('a')['href'] if title_elem else \"No Link\"\n",
        "            citations = result.select_one('.cl-paper-citations').text.strip() if result.select_one('.cl-paper-citations') else \"N/A\"\n",
        "            papers.append({\"title\": title, \"link\": link, \"citations\": citations})\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching from Semantic Scholar: {e}\")\n",
        "\n",
        "    return papers\n",
        "\n",
        "def fetch_microsoft_academic_papers(staff_name):\n",
        "    \"\"\"\n",
        "    Placeholder function for Microsoft Academic (retired in December 2021).\n",
        "    Returns an empty list since the service is no longer available.\n",
        "    \"\"\"\n",
        "    print(\"Microsoft Academic is no longer available. It was retired in December 2021.\")\n",
        "    return []\n",
        "\n",
        "def fetch_research_papers(staff_name, college_name):\n",
        "    papers = []\n",
        "    papers += fetch_google_scholar_papers(staff_name, college_name)\n",
        "    papers += fetch_researchgate_papers(staff_name)\n",
        "    papers += fetch_academia_papers(staff_name)\n",
        "    papers += fetch_web_of_science_papers(staff_name, college_name)\n",
        "    papers += fetch_semantic_scholar_papers(staff_name)\n",
        "    papers += fetch_microsoft_academic_papers(staff_name)  \\\n",
        "    return papers\n",
        "\n",
        "# Take user input\n",
        "staff_name = input(\"Enter the staff's name: \")\n",
        "college_name = input(\"Enter the college name: \")\n",
        "\n",
        "print(f\"\\nFetching research papers for {staff_name} from {college_name}...\\n\")\n",
        "papers = fetch_research_papers(staff_name, college_name)\n",
        "\n",
        "if papers:\n",
        "    print(f\"Found {len(papers)} papers:\\n\")\n",
        "    for i, paper in enumerate(papers, start=1):\n",
        "        print(f\"{i}. Title: {paper['title']}\")\n",
        "        print(f\"   Link: {paper['link']}\")\n",
        "        print(f\"   Citations: {paper['citations']}\\n\")\n",
        "else:\n",
        "    print(\"No papers found.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0nYlMbcwNeUo",
        "outputId": "b099a849-928c-4f7c-89be-f2465c6f2b07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the staff's name: C. Heltin Genitha\n",
            "Enter the college name: St. Joseph's College of Engineering\n",
            "\n",
            "Fetching research papers for C. Heltin Genitha from St. Joseph's College of Engineering...\n",
            "\n",
            "Error fetching from ResearchGate: 403 Client Error: Forbidden for url: https://www.researchgate.net/search/publication?q=C.%20Heltin%20Genitha\n",
            "Microsoft Academic is no longer available. It was retired in December 2021.\n",
            "Found 10 papers:\n",
            "\n",
            "1. Title: Automated Framework for the Tuberculosis Detection and Classification in X-Ray Images Using Deep Learning Algorithm\n",
            "   Link: https://ieeexplore.ieee.org/abstract/document/10331715/\n",
            "   Citations: Opslaan Citeren Geciteerd door 3 Verwante artikelen  \n",
            "\n",
            "2. Title: Automatic Framework for the Detection of Fish Aggregation in Acoustic Images Using Deep Learning Algorithms\n",
            "   Link: https://ieeexplore.ieee.org/abstract/document/10689790/\n",
            "   Citations: Opslaan Citeren Verwante artikelen  \n",
            "\n",
            "3. Title: A hybrid approach to super-resolution mapping of remotely sensed multi-spectral satellite images using genetic algorithm and Hopfield neural network\n",
            "   Link: https://link.springer.com/article/10.1007/s12524-018-0905-9\n",
            "   Citations: Opslaan Citeren Geciteerd door 6 Verwante artikelen Alle 6 versies  \n",
            "\n",
            "4. Title: Sub-pixel Classification using FCM and FWCM Algorithms\n",
            "   Link: https://ieeexplore.ieee.org/abstract/document/6921929/\n",
            "   Citations: Opslaan Citeren Geciteerd door 1 Verwante artikelen Alle 4 versies  \n",
            "\n",
            "5. Title: Comparative analysis for the detection of marine vessels from satellite images using FCM and marker-controlled watershed segmentation algorithm\n",
            "   Link: https://link.springer.com/article/10.1007/s12524-020-01148-x\n",
            "   Citations: Opslaan Citeren Geciteerd door 7 Verwante artikelen Alle 5 versies  \n",
            "\n",
            "6. Title: Automatic Segmentation and Extraction of Skin Lesion in Dermoscopic images using Image Processing\n",
            "   Link: https://ieeexplore.ieee.org/abstract/document/10465429/\n",
            "   Citations: Opslaan Citeren Verwante artikelen  \n",
            "\n",
            "7. Title: AI based Real-Time Traffic Signal Control System using Machine Learning\n",
            "   Link: https://ieeexplore.ieee.org/abstract/document/10193319/\n",
            "   Citations: Opslaan Citeren Geciteerd door 5 Verwante artikelen  \n",
            "\n",
            "8. Title: Automated breast boundary segmentation to improve the accuracy of identifying abnormalities in breast thermograms\n",
            "   Link: https://www.tandfonline.com/doi/abs/10.1080/03772063.2023.2194277\n",
            "   Citations: Opslaan Citeren Geciteerd door 2 Verwante artikelen Alle 2 versies  \n",
            "\n",
            "9. Title: [PDF][PDF] A Novel Technique for Multi-Spectral Image Compression Using SPIHT Algorithm\n",
            "   Link: https://www.researchgate.net/profile/Heltin-Genitha-Cyril/publication/283495291_A_Novel_Technique_for_Multi-Spectral_Image_Compression_Using_SPIHT_Algorithm/links/563ae2a408aeed0531dcc240/A-Novel-Technique-for-Multi-Spectral-Image-Compression-Using-SPIHT-Algorithm.pdf\n",
            "   Citations: Opslaan Citeren Verwante artikelen Alle 2 versies  HTML-versie \n",
            "\n",
            "10. Title: A technique for multi-spectral satellite image compression using EZW algorithm\n",
            "   Link: https://ieeexplore.ieee.org/abstract/document/7988040/\n",
            "   Citations: Opslaan Citeren Geciteerd door 7 Verwante artikelen  \n",
            "\n"
          ]
        }
      ]
    }
  ]
}